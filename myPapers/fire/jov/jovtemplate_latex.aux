\relax 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\@writefile{toc}{\contentsline {section}{Introduction}{1}{section*.1}}
\@writefile{toc}{\contentsline {section}{Fire in the natural environment}{2}{section*.2}}
\@writefile{toc}{\contentsline {section}{How is fire represented?}{2}{section*.3}}
\@writefile{toc}{\contentsline {section}{Post-comparison or convolution?}{3}{section*.4}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{subfig-1:dummy}{{1a}{4}{Subfigure 1a\relax }{subfigure.1.1}{}}
\newlabel{sub@subfig-1:dummy}{{(a)}{a}{Subfigure 1a\relax }{subfigure.1.1}{}}
\newlabel{subfig-2:dummy}{{1b}{4}{Subfigure 1b\relax }{subfigure.1.2}{}}
\newlabel{sub@subfig-2:dummy}{{(b)}{b}{Subfigure 1b\relax }{subfigure.1.2}{}}
\newlabel{subfig-2:dummy}{{1c}{4}{Subfigure 1c\relax }{subfigure.1.3}{}}
\newlabel{sub@subfig-2:dummy}{{(c)}{c}{Subfigure 1c\relax }{subfigure.1.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces In a delayed match-to-sample task, subjects were asked to select which of two candidate clips contained a target clip. Accuracy decreased with candidate length, showing that the comparison process is not analogous to convolution. Accuracy increased with sample length; the previous effect is therefore not due to higher clips being more confusable.\relax }}{4}{figure.caption.5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {A delayed match-to-sample paradigm was re-used several times in this study. Subjects selected which of two candidate clips contained a slightly shorter sample clip. Accuracy ranged from 50\% to 100\%.}}}{4}{subfigure.1.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {\textbf {Experiment 1.} Increasing candidate length lowered accuracy, showing that the sample-candidate comparison process depends on candidate length.}}}{4}{subfigure.1.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {\textbf {Experiment 2.} Increasing sample length raised accuracy, showing that longer samples aid recognition.}}}{4}{subfigure.1.3}}
\newlabel{fig:dummy}{{1}{4}{In a delayed match-to-sample task, subjects were asked to select which of two candidate clips contained a target clip. Accuracy decreased with candidate length, showing that the comparison process is not analogous to convolution. Accuracy increased with sample length; the previous effect is therefore not due to higher clips being more confusable.\relax \relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {section}{What do these representations describe?}{4}{section*.6}}
\@writefile{toc}{\contentsline {section}{Are these representations specialised?}{5}{section*.8}}
\citation{farah1995causes}
\citation{freire2000face}
\citation{yovel2005neural}
\citation{freire2000face}
\@writefile{toc}{\contentsline {section}{Are fire representations tuned to direction?}{6}{section*.9}}
\@writefile{toc}{\contentsline {section}{Conclusions}{6}{section*.10}}
\bibdata{jovtemplate_latex}
\bibstyle{jovcite}
\newlabel{subfig-2:dummy}{{2a}{8}{Subfigure 2a\relax }{subfigure.2.1}{}}
\newlabel{sub@subfig-2:dummy}{{(a)}{a}{Subfigure 2a\relax }{subfigure.2.1}{}}
\newlabel{subfig-2:dummy}{{2b}{8}{Subfigure 2b\relax }{subfigure.2.2}{}}
\newlabel{sub@subfig-2:dummy}{{(b)}{b}{Subfigure 2b\relax }{subfigure.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textbf  {Experiment 3.} In a delayed-match-to-sample task, sample clips were altered by colour inversion, temporal inversion, and spatial inversion. This disrupted colour information, temporal order of features and spatial layout of features. Subjects needed to match a stored, altered percept with an incoming, unaltered clip. Decreases in accuracy showed which types of information were most important for matching: spatial configuration, followed by temporal order.\relax }}{8}{figure.caption.7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {To alter their natural colour, clips were processed by expression in HSV colour space and rotation through 180\ensuremath {\SI@fstyle {\no@qsk \ensuremath {^{\circ }}}}in the hue plane. Clips were also inverted. }}}{8}{subfigure.2.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {The delayed match-to-sample paradigm was reapplied, with alterations (conversion to monochrome, reversed playback, and inverted playback) made to the sample only. Encodings of the sample, with partial information, thus had to be matched to unaltered candidates. Error bars show 95\% confidence intervals.}}}{8}{subfigure.2.2}}
\newlabel{fig:dummy}{{2}{8}{\textbf {Experiment 3.} In a delayed-match-to-sample task, sample clips were altered by colour inversion, temporal inversion, and spatial inversion. This disrupted colour information, temporal order of features and spatial layout of features. Subjects needed to match a stored, altered percept with an incoming, unaltered clip. Decreases in accuracy showed which types of information were most important for matching: spatial configuration, followed by temporal order.\relax \relax }{figure.caption.7}{}}
